# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 1.9777e-05
go_gc_duration_seconds{quantile="0.25"} 4.4512e-05
go_gc_duration_seconds{quantile="0.5"} 5.1137e-05
go_gc_duration_seconds{quantile="0.75"} 6.2722e-05
go_gc_duration_seconds{quantile="1"} 0.000231978
go_gc_duration_seconds_sum 0.003897715
go_gc_duration_seconds_count 64
# HELP go_goroutines Number of goroutines that currently exist.
# TYPE go_goroutines gauge
go_goroutines 421
# HELP go_info Information about the Go environment.
# TYPE go_info gauge
go_info{version="go1.19.4"} 1
# HELP go_memstats_alloc_bytes Number of bytes allocated and still in use.
# TYPE go_memstats_alloc_bytes gauge
go_memstats_alloc_bytes 6.40812064e+08
# HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed.
# TYPE go_memstats_alloc_bytes_total counter
go_memstats_alloc_bytes_total 1.2000177352e+10
# HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table.
# TYPE go_memstats_buck_hash_sys_bytes gauge
go_memstats_buck_hash_sys_bytes 1.736721e+06
# HELP go_memstats_frees_total Total number of frees.
# TYPE go_memstats_frees_total counter
go_memstats_frees_total 5.4624339e+07
# HELP go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata.
# TYPE go_memstats_gc_sys_bytes gauge
go_memstats_gc_sys_bytes 5.1359224e+07
# HELP go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use.
# TYPE go_memstats_heap_alloc_bytes gauge
go_memstats_heap_alloc_bytes 6.40812064e+08
# HELP go_memstats_heap_idle_bytes Number of heap bytes waiting to be used.
# TYPE go_memstats_heap_idle_bytes gauge
go_memstats_heap_idle_bytes 4.77642752e+08
# HELP go_memstats_heap_inuse_bytes Number of heap bytes that are in use.
# TYPE go_memstats_heap_inuse_bytes gauge
go_memstats_heap_inuse_bytes 7.22485248e+08
# HELP go_memstats_heap_objects Number of allocated objects.
# TYPE go_memstats_heap_objects gauge
go_memstats_heap_objects 2.461396e+06
# HELP go_memstats_heap_released_bytes Number of heap bytes released to OS.
# TYPE go_memstats_heap_released_bytes gauge
go_memstats_heap_released_bytes 1.95158016e+08
# HELP go_memstats_heap_sys_bytes Number of heap bytes obtained from system.
# TYPE go_memstats_heap_sys_bytes gauge
go_memstats_heap_sys_bytes 1.200128e+09
# HELP go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection.
# TYPE go_memstats_last_gc_time_seconds gauge
go_memstats_last_gc_time_seconds 1.6984120693489513e+09
# HELP go_memstats_lookups_total Total number of pointer lookups.
# TYPE go_memstats_lookups_total counter
go_memstats_lookups_total 0
# HELP go_memstats_mallocs_total Total number of mallocs.
# TYPE go_memstats_mallocs_total counter
go_memstats_mallocs_total 5.7085735e+07
# HELP go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures.
# TYPE go_memstats_mcache_inuse_bytes gauge
go_memstats_mcache_inuse_bytes 24000
# HELP go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system.
# TYPE go_memstats_mcache_sys_bytes gauge
go_memstats_mcache_sys_bytes 31200
# HELP go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures.
# TYPE go_memstats_mspan_inuse_bytes gauge
go_memstats_mspan_inuse_bytes 6.176016e+06
# HELP go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system.
# TYPE go_memstats_mspan_sys_bytes gauge
go_memstats_mspan_sys_bytes 9.795744e+06
# HELP go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place.
# TYPE go_memstats_next_gc_bytes gauge
go_memstats_next_gc_bytes 1.280937264e+09
# HELP go_memstats_other_sys_bytes Number of bytes used for other system allocations.
# TYPE go_memstats_other_sys_bytes gauge
go_memstats_other_sys_bytes 4.113807e+06
# HELP go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator.
# TYPE go_memstats_stack_inuse_bytes gauge
go_memstats_stack_inuse_bytes 7.831552e+06
# HELP go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator.
# TYPE go_memstats_stack_sys_bytes gauge
go_memstats_stack_sys_bytes 7.831552e+06
# HELP go_memstats_sys_bytes Number of bytes obtained from system.
# TYPE go_memstats_sys_bytes gauge
go_memstats_sys_bytes 1.274996248e+09
# HELP go_threads Number of OS threads created.
# TYPE go_threads gauge
go_threads 26
# HELP net_conntrack_dialer_conn_attempted_total Total number of connections attempted by the given dialer a given name.
# TYPE net_conntrack_dialer_conn_attempted_total counter
net_conntrack_dialer_conn_attempted_total{dialer_name="default"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="envoy-stats"} 123
net_conntrack_dialer_conn_attempted_total{dialer_name="istiod"} 5
net_conntrack_dialer_conn_attempted_total{dialer_name="kubernetes-apiservers"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="kubernetes-nodes"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="kubernetes-nodes-cadvisor"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="kubernetes-pods"} 127
net_conntrack_dialer_conn_attempted_total{dialer_name="kubernetes-pods-slow"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="kubernetes-service-endpoints"} 1967
net_conntrack_dialer_conn_attempted_total{dialer_name="kubernetes-service-endpoints-slow"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="kubernetes-services"} 0
net_conntrack_dialer_conn_attempted_total{dialer_name="node-info"} 53
net_conntrack_dialer_conn_attempted_total{dialer_name="node_exporter"} 333
net_conntrack_dialer_conn_attempted_total{dialer_name="prometheus"} 1
net_conntrack_dialer_conn_attempted_total{dialer_name="prometheus-pushgateway"} 0
# HELP net_conntrack_dialer_conn_closed_total Total number of connections closed which originated from the dialer of a given name.
# TYPE net_conntrack_dialer_conn_closed_total counter
net_conntrack_dialer_conn_closed_total{dialer_name="default"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="envoy-stats"} 34
net_conntrack_dialer_conn_closed_total{dialer_name="istiod"} 2
net_conntrack_dialer_conn_closed_total{dialer_name="kubernetes-apiservers"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="kubernetes-nodes"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="kubernetes-nodes-cadvisor"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="kubernetes-pods"} 36
net_conntrack_dialer_conn_closed_total{dialer_name="kubernetes-pods-slow"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="kubernetes-service-endpoints"} 1677
net_conntrack_dialer_conn_closed_total{dialer_name="kubernetes-service-endpoints-slow"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="kubernetes-services"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="node-info"} 6
net_conntrack_dialer_conn_closed_total{dialer_name="node_exporter"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="prometheus"} 0
net_conntrack_dialer_conn_closed_total{dialer_name="prometheus-pushgateway"} 0
# HELP net_conntrack_dialer_conn_established_total Total number of connections successfully established by the given dialer a given name.
# TYPE net_conntrack_dialer_conn_established_total counter
net_conntrack_dialer_conn_established_total{dialer_name="default"} 0
net_conntrack_dialer_conn_established_total{dialer_name="envoy-stats"} 71
net_conntrack_dialer_conn_established_total{dialer_name="istiod"} 4
net_conntrack_dialer_conn_established_total{dialer_name="kubernetes-apiservers"} 1
net_conntrack_dialer_conn_established_total{dialer_name="kubernetes-nodes"} 1
net_conntrack_dialer_conn_established_total{dialer_name="kubernetes-nodes-cadvisor"} 1
net_conntrack_dialer_conn_established_total{dialer_name="kubernetes-pods"} 76
net_conntrack_dialer_conn_established_total{dialer_name="kubernetes-pods-slow"} 0
net_conntrack_dialer_conn_established_total{dialer_name="kubernetes-service-endpoints"} 1684
net_conntrack_dialer_conn_established_total{dialer_name="kubernetes-service-endpoints-slow"} 0
net_conntrack_dialer_conn_established_total{dialer_name="kubernetes-services"} 0
net_conntrack_dialer_conn_established_total{dialer_name="node-info"} 10
net_conntrack_dialer_conn_established_total{dialer_name="node_exporter"} 0
net_conntrack_dialer_conn_established_total{dialer_name="prometheus"} 1
net_conntrack_dialer_conn_established_total{dialer_name="prometheus-pushgateway"} 0
# HELP net_conntrack_dialer_conn_failed_total Total number of connections failed to dial by the dialer a given name.
# TYPE net_conntrack_dialer_conn_failed_total counter
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="default",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="envoy-stats",reason="refused"} 43
net_conntrack_dialer_conn_failed_total{dialer_name="envoy-stats",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="envoy-stats",reason="timeout"} 9
net_conntrack_dialer_conn_failed_total{dialer_name="envoy-stats",reason="unknown"} 52
net_conntrack_dialer_conn_failed_total{dialer_name="istiod",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="istiod",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="istiod",reason="timeout"} 1
net_conntrack_dialer_conn_failed_total{dialer_name="istiod",reason="unknown"} 1
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-apiservers",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-apiservers",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-apiservers",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-apiservers",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-nodes",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-nodes",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-nodes",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-nodes",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-nodes-cadvisor",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-nodes-cadvisor",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-nodes-cadvisor",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-nodes-cadvisor",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-pods",reason="refused"} 42
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-pods",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-pods",reason="timeout"} 9
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-pods",reason="unknown"} 51
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-pods-slow",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-pods-slow",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-pods-slow",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-pods-slow",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-service-endpoints",reason="refused"} 283
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-service-endpoints",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-service-endpoints",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-service-endpoints",reason="unknown"} 283
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-service-endpoints-slow",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-service-endpoints-slow",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-service-endpoints-slow",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-service-endpoints-slow",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-services",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-services",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-services",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="kubernetes-services",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="node-info",reason="refused"} 43
net_conntrack_dialer_conn_failed_total{dialer_name="node-info",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="node-info",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="node-info",reason="unknown"} 43
net_conntrack_dialer_conn_failed_total{dialer_name="node_exporter",reason="refused"} 333
net_conntrack_dialer_conn_failed_total{dialer_name="node_exporter",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="node_exporter",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="node_exporter",reason="unknown"} 333
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus",reason="unknown"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus-pushgateway",reason="refused"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus-pushgateway",reason="resolution"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus-pushgateway",reason="timeout"} 0
net_conntrack_dialer_conn_failed_total{dialer_name="prometheus-pushgateway",reason="unknown"} 0
# HELP net_conntrack_listener_conn_accepted_total Total number of connections opened to the listener of a given name.
# TYPE net_conntrack_listener_conn_accepted_total counter
net_conntrack_listener_conn_accepted_total{listener_name="http"} 1331
# HELP net_conntrack_listener_conn_closed_total Total number of connections closed that were made to the listener of a given name.
# TYPE net_conntrack_listener_conn_closed_total counter
net_conntrack_listener_conn_closed_total{listener_name="http"} 1329
# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.
# TYPE process_cpu_seconds_total counter
process_cpu_seconds_total 90.7
# HELP process_max_fds Maximum number of open file descriptors.
# TYPE process_max_fds gauge
process_max_fds 1.048576e+06
# HELP process_open_fds Number of open file descriptors.
# TYPE process_open_fds gauge
process_open_fds 110
# HELP process_resident_memory_bytes Resident memory size in bytes.
# TYPE process_resident_memory_bytes gauge
process_resident_memory_bytes 1.116401664e+09
# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.
# TYPE process_start_time_seconds gauge
process_start_time_seconds 1.6984070782e+09
# HELP process_virtual_memory_bytes Virtual memory size in bytes.
# TYPE process_virtual_memory_bytes gauge
process_virtual_memory_bytes 2.1474304e+09
# HELP process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes.
# TYPE process_virtual_memory_max_bytes gauge
process_virtual_memory_max_bytes 1.8446744073709552e+19
# HELP prometheus_api_remote_read_queries The current number of remote read queries being executed or waiting.
# TYPE prometheus_api_remote_read_queries gauge
prometheus_api_remote_read_queries 0
# HELP prometheus_build_info A metric with a constant '1' value labeled by version, revision, branch, goversion from which prometheus was built, and the goos and goarch for the build.
# TYPE prometheus_build_info gauge
prometheus_build_info{branch="HEAD",goarch="amd64",goos="linux",goversion="go1.19.4",revision="c0d8a56c69014279464c0e15d8bfb0e153af0dab",version="2.41.0"} 1
# HELP prometheus_config_last_reload_success_timestamp_seconds Timestamp of the last successful configuration reload.
# TYPE prometheus_config_last_reload_success_timestamp_seconds gauge
prometheus_config_last_reload_success_timestamp_seconds 1.6984070782957292e+09
# HELP prometheus_config_last_reload_successful Whether the last configuration reload attempt was successful.
# TYPE prometheus_config_last_reload_successful gauge
prometheus_config_last_reload_successful 1
# HELP prometheus_engine_queries The current number of queries being executed or waiting.
# TYPE prometheus_engine_queries gauge
prometheus_engine_queries 0
# HELP prometheus_engine_queries_concurrent_max The max number of concurrent queries.
# TYPE prometheus_engine_queries_concurrent_max gauge
prometheus_engine_queries_concurrent_max 20
# HELP prometheus_engine_query_duration_seconds Query timings
# TYPE prometheus_engine_query_duration_seconds summary
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.5"} NaN
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.9"} NaN
prometheus_engine_query_duration_seconds{slice="inner_eval",quantile="0.99"} NaN
prometheus_engine_query_duration_seconds_sum{slice="inner_eval"} 0
prometheus_engine_query_duration_seconds_count{slice="inner_eval"} 0
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.5"} NaN
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.9"} NaN
prometheus_engine_query_duration_seconds{slice="prepare_time",quantile="0.99"} NaN
prometheus_engine_query_duration_seconds_sum{slice="prepare_time"} 0
prometheus_engine_query_duration_seconds_count{slice="prepare_time"} 0
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.5"} NaN
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.9"} NaN
prometheus_engine_query_duration_seconds{slice="queue_time",quantile="0.99"} NaN
prometheus_engine_query_duration_seconds_sum{slice="queue_time"} 0
prometheus_engine_query_duration_seconds_count{slice="queue_time"} 0
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.5"} NaN
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.9"} NaN
prometheus_engine_query_duration_seconds{slice="result_sort",quantile="0.99"} NaN
prometheus_engine_query_duration_seconds_sum{slice="result_sort"} 0
prometheus_engine_query_duration_seconds_count{slice="result_sort"} 0
# HELP prometheus_engine_query_log_enabled State of the query log.
# TYPE prometheus_engine_query_log_enabled gauge
prometheus_engine_query_log_enabled 0
# HELP prometheus_engine_query_log_failures_total The number of query log failures.
# TYPE prometheus_engine_query_log_failures_total counter
prometheus_engine_query_log_failures_total 0
# HELP prometheus_http_request_duration_seconds Histogram of latencies for HTTP requests.
# TYPE prometheus_http_request_duration_seconds histogram
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="0.1"} 330
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="0.2"} 330
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="0.4"} 330
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="1"} 330
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="3"} 330
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="8"} 330
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="20"} 330
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="60"} 330
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="120"} 330
prometheus_http_request_duration_seconds_bucket{handler="/-/healthy",le="+Inf"} 330
prometheus_http_request_duration_seconds_sum{handler="/-/healthy"} 0.0017331330000000002
prometheus_http_request_duration_seconds_count{handler="/-/healthy"} 330
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="0.1"} 999
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="0.2"} 999
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="0.4"} 999
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="1"} 999
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="3"} 999
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="8"} 999
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="20"} 999
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="60"} 999
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="120"} 999
prometheus_http_request_duration_seconds_bucket{handler="/-/ready",le="+Inf"} 999
prometheus_http_request_duration_seconds_sum{handler="/-/ready"} 0.008278179000000014
prometheus_http_request_duration_seconds_count{handler="/-/ready"} 999
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.1"} 333
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.2"} 333
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="0.4"} 333
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="1"} 333
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="3"} 333
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="8"} 333
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="20"} 333
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="60"} 333
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="120"} 333
prometheus_http_request_duration_seconds_bucket{handler="/metrics",le="+Inf"} 333
prometheus_http_request_duration_seconds_sum{handler="/metrics"} 0.9131341919999998
prometheus_http_request_duration_seconds_count{handler="/metrics"} 333
# HELP prometheus_http_requests_total Counter of HTTP requests.
# TYPE prometheus_http_requests_total counter
prometheus_http_requests_total{code="200",handler="/-/healthy"} 330
prometheus_http_requests_total{code="200",handler="/-/ready"} 999
prometheus_http_requests_total{code="200",handler="/metrics"} 333
# HELP prometheus_http_response_size_bytes Histogram of response size for HTTP requests.
# TYPE prometheus_http_response_size_bytes histogram
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="100"} 330
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1000"} 330
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="10000"} 330
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="100000"} 330
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+06"} 330
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+07"} 330
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+08"} 330
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="1e+09"} 330
prometheus_http_response_size_bytes_bucket{handler="/-/healthy",le="+Inf"} 330
prometheus_http_response_size_bytes_sum{handler="/-/healthy"} 9900
prometheus_http_response_size_bytes_count{handler="/-/healthy"} 330
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="100"} 999
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1000"} 999
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="10000"} 999
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="100000"} 999
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+06"} 999
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+07"} 999
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+08"} 999
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="1e+09"} 999
prometheus_http_response_size_bytes_bucket{handler="/-/ready",le="+Inf"} 999
prometheus_http_response_size_bytes_sum{handler="/-/ready"} 27972
prometheus_http_response_size_bytes_count{handler="/-/ready"} 999
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="100"} 0
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1000"} 0
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="10000"} 5
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="100000"} 333
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+06"} 333
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+07"} 333
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+08"} 333
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="1e+09"} 333
prometheus_http_response_size_bytes_bucket{handler="/metrics",le="+Inf"} 333
prometheus_http_response_size_bytes_sum{handler="/metrics"} 3.47817e+06
prometheus_http_response_size_bytes_count{handler="/metrics"} 333
# HELP prometheus_notifications_alertmanagers_discovered The number of alertmanagers discovered and active.
# TYPE prometheus_notifications_alertmanagers_discovered gauge
prometheus_notifications_alertmanagers_discovered 0
# HELP prometheus_notifications_dropped_total Total number of alerts dropped due to errors when sending to Alertmanager.
# TYPE prometheus_notifications_dropped_total counter
prometheus_notifications_dropped_total 0
# HELP prometheus_notifications_queue_capacity The capacity of the alert notifications queue.
# TYPE prometheus_notifications_queue_capacity gauge
prometheus_notifications_queue_capacity 10000
# HELP prometheus_notifications_queue_length The number of alert notifications in the queue.
# TYPE prometheus_notifications_queue_length gauge
prometheus_notifications_queue_length 0
# HELP prometheus_ready Whether Prometheus startup was fully completed and the server is ready for normal operation.
# TYPE prometheus_ready gauge
prometheus_ready 1
# HELP prometheus_remote_storage_exemplars_in_total Exemplars in to remote storage, compare to exemplars out for queue managers.
# TYPE prometheus_remote_storage_exemplars_in_total counter
prometheus_remote_storage_exemplars_in_total 0
# HELP prometheus_remote_storage_highest_timestamp_in_seconds Highest timestamp that has come into the remote storage via the Appender interface, in seconds since epoch.
# TYPE prometheus_remote_storage_highest_timestamp_in_seconds gauge
prometheus_remote_storage_highest_timestamp_in_seconds 1.698412072e+09
# HELP prometheus_remote_storage_histograms_in_total HistogramSamples in to remote storage, compare to histograms out for queue managers.
# TYPE prometheus_remote_storage_histograms_in_total counter
prometheus_remote_storage_histograms_in_total 0
# HELP prometheus_remote_storage_samples_in_total Samples in to remote storage, compare to samples out for queue managers.
# TYPE prometheus_remote_storage_samples_in_total counter
prometheus_remote_storage_samples_in_total 3.5337881e+07
# HELP prometheus_remote_storage_string_interner_zero_reference_releases_total The number of times release has been called for strings that are not interned.
# TYPE prometheus_remote_storage_string_interner_zero_reference_releases_total counter
prometheus_remote_storage_string_interner_zero_reference_releases_total 0
# HELP prometheus_rule_evaluation_duration_seconds The duration for a rule to execute.
# TYPE prometheus_rule_evaluation_duration_seconds summary
prometheus_rule_evaluation_duration_seconds{quantile="0.5"} NaN
prometheus_rule_evaluation_duration_seconds{quantile="0.9"} NaN
prometheus_rule_evaluation_duration_seconds{quantile="0.99"} NaN
prometheus_rule_evaluation_duration_seconds_sum 0
prometheus_rule_evaluation_duration_seconds_count 0
# HELP prometheus_rule_group_duration_seconds The duration of rule group evaluations.
# TYPE prometheus_rule_group_duration_seconds summary
prometheus_rule_group_duration_seconds{quantile="0.01"} NaN
prometheus_rule_group_duration_seconds{quantile="0.05"} NaN
prometheus_rule_group_duration_seconds{quantile="0.5"} NaN
prometheus_rule_group_duration_seconds{quantile="0.9"} NaN
prometheus_rule_group_duration_seconds{quantile="0.99"} NaN
prometheus_rule_group_duration_seconds_sum 0
prometheus_rule_group_duration_seconds_count 0
# HELP prometheus_sd_azure_failures_total Number of Azure service discovery refresh failures.
# TYPE prometheus_sd_azure_failures_total counter
prometheus_sd_azure_failures_total 0
# HELP prometheus_sd_consul_rpc_duration_seconds The duration of a Consul RPC call in seconds.
# TYPE prometheus_sd_consul_rpc_duration_seconds summary
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.5"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.9"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="service",endpoint="catalog",quantile="0.99"} NaN
prometheus_sd_consul_rpc_duration_seconds_sum{call="service",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds_count{call="service",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.5"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.9"} NaN
prometheus_sd_consul_rpc_duration_seconds{call="services",endpoint="catalog",quantile="0.99"} NaN
prometheus_sd_consul_rpc_duration_seconds_sum{call="services",endpoint="catalog"} 0
prometheus_sd_consul_rpc_duration_seconds_count{call="services",endpoint="catalog"} 0
# HELP prometheus_sd_consul_rpc_failures_total The number of Consul RPC call failures.
# TYPE prometheus_sd_consul_rpc_failures_total counter
prometheus_sd_consul_rpc_failures_total 0
# HELP prometheus_sd_discovered_targets Current number of discovered targets.
# TYPE prometheus_sd_discovered_targets gauge
prometheus_sd_discovered_targets{config="envoy-stats",name="scrape"} 296
prometheus_sd_discovered_targets{config="istiod",name="scrape"} 37
prometheus_sd_discovered_targets{config="kubernetes-apiservers",name="scrape"} 133
prometheus_sd_discovered_targets{config="kubernetes-nodes",name="scrape"} 4
prometheus_sd_discovered_targets{config="kubernetes-nodes-cadvisor",name="scrape"} 4
prometheus_sd_discovered_targets{config="kubernetes-pods",name="scrape"} 296
prometheus_sd_discovered_targets{config="kubernetes-pods-slow",name="scrape"} 296
prometheus_sd_discovered_targets{config="kubernetes-service-endpoints",name="scrape"} 133
prometheus_sd_discovered_targets{config="kubernetes-service-endpoints-slow",name="scrape"} 133
prometheus_sd_discovered_targets{config="kubernetes-services",name="scrape"} 79
prometheus_sd_discovered_targets{config="node-info",name="scrape"} 4
prometheus_sd_discovered_targets{config="node_exporter",name="scrape"} 1
prometheus_sd_discovered_targets{config="prometheus",name="scrape"} 1
prometheus_sd_discovered_targets{config="prometheus-pushgateway",name="scrape"} 79
# HELP prometheus_sd_dns_lookup_failures_total The number of DNS-SD lookup failures.
# TYPE prometheus_sd_dns_lookup_failures_total counter
prometheus_sd_dns_lookup_failures_total 0
# HELP prometheus_sd_dns_lookups_total The number of DNS-SD lookups.
# TYPE prometheus_sd_dns_lookups_total counter
prometheus_sd_dns_lookups_total 0
# HELP prometheus_sd_failed_configs Current number of service discovery configurations that failed to load.
# TYPE prometheus_sd_failed_configs gauge
prometheus_sd_failed_configs{name="notify"} 0
prometheus_sd_failed_configs{name="scrape"} 0
# HELP prometheus_sd_file_read_errors_total The number of File-SD read errors.
# TYPE prometheus_sd_file_read_errors_total counter
prometheus_sd_file_read_errors_total 0
# HELP prometheus_sd_file_scan_duration_seconds The duration of the File-SD scan in seconds.
# TYPE prometheus_sd_file_scan_duration_seconds summary
prometheus_sd_file_scan_duration_seconds{quantile="0.5"} NaN
prometheus_sd_file_scan_duration_seconds{quantile="0.9"} NaN
prometheus_sd_file_scan_duration_seconds{quantile="0.99"} NaN
prometheus_sd_file_scan_duration_seconds_sum 0
prometheus_sd_file_scan_duration_seconds_count 0
# HELP prometheus_sd_file_watcher_errors_total The number of File-SD errors caused by filesystem watch failures.
# TYPE prometheus_sd_file_watcher_errors_total counter
prometheus_sd_file_watcher_errors_total 0
# HELP prometheus_sd_http_failures_total Number of HTTP service discovery refresh failures.
# TYPE prometheus_sd_http_failures_total counter
prometheus_sd_http_failures_total 0
# HELP prometheus_sd_kubernetes_events_total The number of Kubernetes events handled.
# TYPE prometheus_sd_kubernetes_events_total counter
prometheus_sd_kubernetes_events_total{event="add",role="endpoints"} 64
prometheus_sd_kubernetes_events_total{event="add",role="endpointslice"} 0
prometheus_sd_kubernetes_events_total{event="add",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="add",role="node"} 4
prometheus_sd_kubernetes_events_total{event="add",role="pod"} 153
prometheus_sd_kubernetes_events_total{event="add",role="service"} 122
prometheus_sd_kubernetes_events_total{event="delete",role="endpoints"} 3
prometheus_sd_kubernetes_events_total{event="delete",role="endpointslice"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="node"} 0
prometheus_sd_kubernetes_events_total{event="delete",role="pod"} 42
prometheus_sd_kubernetes_events_total{event="delete",role="service"} 6
prometheus_sd_kubernetes_events_total{event="update",role="endpoints"} 675
prometheus_sd_kubernetes_events_total{event="update",role="endpointslice"} 0
prometheus_sd_kubernetes_events_total{event="update",role="ingress"} 0
prometheus_sd_kubernetes_events_total{event="update",role="node"} 110
prometheus_sd_kubernetes_events_total{event="update",role="pod"} 1423
prometheus_sd_kubernetes_events_total{event="update",role="service"} 940
# HELP prometheus_sd_kubernetes_http_request_duration_seconds Summary of latencies for HTTP requests to the Kubernetes API by endpoint.
# TYPE prometheus_sd_kubernetes_http_request_duration_seconds summary
prometheus_sd_kubernetes_http_request_duration_seconds_sum{endpoint="/api/v1/endpoints"} 0.007561447
prometheus_sd_kubernetes_http_request_duration_seconds_count{endpoint="/api/v1/endpoints"} 1
prometheus_sd_kubernetes_http_request_duration_seconds_sum{endpoint="/api/v1/namespaces/%7Bnamespace%7D/endpoints"} 0.007616764
prometheus_sd_kubernetes_http_request_duration_seconds_count{endpoint="/api/v1/namespaces/%7Bnamespace%7D/endpoints"} 1
prometheus_sd_kubernetes_http_request_duration_seconds_sum{endpoint="/api/v1/namespaces/%7Bnamespace%7D/pods"} 0.006059952
prometheus_sd_kubernetes_http_request_duration_seconds_count{endpoint="/api/v1/namespaces/%7Bnamespace%7D/pods"} 1
prometheus_sd_kubernetes_http_request_duration_seconds_sum{endpoint="/api/v1/namespaces/%7Bnamespace%7D/services"} 0.004238738
prometheus_sd_kubernetes_http_request_duration_seconds_count{endpoint="/api/v1/namespaces/%7Bnamespace%7D/services"} 1
prometheus_sd_kubernetes_http_request_duration_seconds_sum{endpoint="/api/v1/nodes"} 0.005139729
prometheus_sd_kubernetes_http_request_duration_seconds_count{endpoint="/api/v1/nodes"} 1
prometheus_sd_kubernetes_http_request_duration_seconds_sum{endpoint="/api/v1/pods"} 0.023231386
prometheus_sd_kubernetes_http_request_duration_seconds_count{endpoint="/api/v1/pods"} 2
prometheus_sd_kubernetes_http_request_duration_seconds_sum{endpoint="/api/v1/services"} 0.014452317
prometheus_sd_kubernetes_http_request_duration_seconds_count{endpoint="/api/v1/services"} 2
# HELP prometheus_sd_kubernetes_http_request_total Total number of HTTP requests to the Kubernetes API by status code.
# TYPE prometheus_sd_kubernetes_http_request_total counter
prometheus_sd_kubernetes_http_request_total{status_code="200"} 115
# HELP prometheus_sd_kubernetes_workqueue_depth Current depth of the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_depth gauge
prometheus_sd_kubernetes_workqueue_depth{queue_name="endpoints"} 0
prometheus_sd_kubernetes_workqueue_depth{queue_name="node"} 0
prometheus_sd_kubernetes_workqueue_depth{queue_name="pod"} 0
prometheus_sd_kubernetes_workqueue_depth{queue_name="service"} 0
# HELP prometheus_sd_kubernetes_workqueue_items_total Total number of items added to the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_items_total counter
prometheus_sd_kubernetes_workqueue_items_total{queue_name="endpoints"} 819
prometheus_sd_kubernetes_workqueue_items_total{queue_name="node"} 114
prometheus_sd_kubernetes_workqueue_items_total{queue_name="pod"} 1616
prometheus_sd_kubernetes_workqueue_items_total{queue_name="service"} 504
# HELP prometheus_sd_kubernetes_workqueue_latency_seconds How long an item stays in the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_latency_seconds summary
prometheus_sd_kubernetes_workqueue_latency_seconds_sum{queue_name="endpoints"} 6.783459379999993
prometheus_sd_kubernetes_workqueue_latency_seconds_count{queue_name="endpoints"} 819
prometheus_sd_kubernetes_workqueue_latency_seconds_sum{queue_name="node"} 0.3915369840000001
prometheus_sd_kubernetes_workqueue_latency_seconds_count{queue_name="node"} 114
prometheus_sd_kubernetes_workqueue_latency_seconds_sum{queue_name="pod"} 10.330878975999997
prometheus_sd_kubernetes_workqueue_latency_seconds_count{queue_name="pod"} 1616
prometheus_sd_kubernetes_workqueue_latency_seconds_sum{queue_name="service"} 5.204195548999999
prometheus_sd_kubernetes_workqueue_latency_seconds_count{queue_name="service"} 504
# HELP prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds Duration of the longest running processor in the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds gauge
prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds{queue_name="endpoints"} 0
prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds{queue_name="node"} 0
prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds{queue_name="pod"} 0
prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds{queue_name="service"} 0
# HELP prometheus_sd_kubernetes_workqueue_unfinished_work_seconds How long an item has remained unfinished in the work queue.
# TYPE prometheus_sd_kubernetes_workqueue_unfinished_work_seconds gauge
prometheus_sd_kubernetes_workqueue_unfinished_work_seconds{queue_name="endpoints"} 0
prometheus_sd_kubernetes_workqueue_unfinished_work_seconds{queue_name="node"} 0
prometheus_sd_kubernetes_workqueue_unfinished_work_seconds{queue_name="pod"} 0
prometheus_sd_kubernetes_workqueue_unfinished_work_seconds{queue_name="service"} 0
# HELP prometheus_sd_kubernetes_workqueue_work_duration_seconds How long processing an item from the work queue takes.
# TYPE prometheus_sd_kubernetes_workqueue_work_duration_seconds summary
prometheus_sd_kubernetes_workqueue_work_duration_seconds_sum{queue_name="endpoints"} 0.09618885500000013
prometheus_sd_kubernetes_workqueue_work_duration_seconds_count{queue_name="endpoints"} 819
prometheus_sd_kubernetes_workqueue_work_duration_seconds_sum{queue_name="node"} 0.022934918
prometheus_sd_kubernetes_workqueue_work_duration_seconds_count{queue_name="node"} 114
prometheus_sd_kubernetes_workqueue_work_duration_seconds_sum{queue_name="pod"} 0.035077292000000024
prometheus_sd_kubernetes_workqueue_work_duration_seconds_count{queue_name="pod"} 1616
prometheus_sd_kubernetes_workqueue_work_duration_seconds_sum{queue_name="service"} 0.0045853390000000025
prometheus_sd_kubernetes_workqueue_work_duration_seconds_count{queue_name="service"} 504
# HELP prometheus_sd_kuma_fetch_duration_seconds The duration of a Kuma MADS fetch call.
# TYPE prometheus_sd_kuma_fetch_duration_seconds summary
prometheus_sd_kuma_fetch_duration_seconds{quantile="0.5"} NaN
prometheus_sd_kuma_fetch_duration_seconds{quantile="0.9"} NaN
prometheus_sd_kuma_fetch_duration_seconds{quantile="0.99"} NaN
prometheus_sd_kuma_fetch_duration_seconds_sum 0
prometheus_sd_kuma_fetch_duration_seconds_count 0
# HELP prometheus_sd_kuma_fetch_failures_total The number of Kuma MADS fetch call failures.
# TYPE prometheus_sd_kuma_fetch_failures_total counter
prometheus_sd_kuma_fetch_failures_total 0
# HELP prometheus_sd_kuma_fetch_skipped_updates_total The number of Kuma MADS fetch calls that result in no updates to the targets.
# TYPE prometheus_sd_kuma_fetch_skipped_updates_total counter
prometheus_sd_kuma_fetch_skipped_updates_total 0
# HELP prometheus_sd_linode_failures_total Number of Linode service discovery refresh failures.
# TYPE prometheus_sd_linode_failures_total counter
prometheus_sd_linode_failures_total 0
# HELP prometheus_sd_nomad_failures_total Number of nomad service discovery refresh failures.
# TYPE prometheus_sd_nomad_failures_total counter
prometheus_sd_nomad_failures_total 0
# HELP prometheus_sd_received_updates_total Total number of update events received from the SD providers.
# TYPE prometheus_sd_received_updates_total counter
prometheus_sd_received_updates_total{name="scrape"} 3059
# HELP prometheus_sd_updates_total Total number of update events sent to the SD consumers.
# TYPE prometheus_sd_updates_total counter
prometheus_sd_updates_total{name="scrape"} 205
# HELP prometheus_target_interval_length_seconds Actual intervals between scrapes.
# TYPE prometheus_target_interval_length_seconds summary
prometheus_target_interval_length_seconds{interval="15s",quantile="0.01"} 14.99905099
prometheus_target_interval_length_seconds{interval="15s",quantile="0.05"} 14.999285526
prometheus_target_interval_length_seconds{interval="15s",quantile="0.5"} 15.00002949
prometheus_target_interval_length_seconds{interval="15s",quantile="0.9"} 15.000591173
prometheus_target_interval_length_seconds{interval="15s",quantile="0.99"} 15.000922033
prometheus_target_interval_length_seconds_sum{interval="15s"} 510660.239402937
prometheus_target_interval_length_seconds_count{interval="15s"} 34044
# HELP prometheus_target_metadata_cache_bytes The number of bytes that are currently used for storing metric metadata in the cache
# TYPE prometheus_target_metadata_cache_bytes gauge
prometheus_target_metadata_cache_bytes{scrape_job="envoy-stats"} 48550
prometheus_target_metadata_cache_bytes{scrape_job="istiod"} 9409
prometheus_target_metadata_cache_bytes{scrape_job="kubernetes-apiservers"} 17991
prometheus_target_metadata_cache_bytes{scrape_job="kubernetes-nodes"} 44647
prometheus_target_metadata_cache_bytes{scrape_job="kubernetes-nodes-cadvisor"} 13404
prometheus_target_metadata_cache_bytes{scrape_job="kubernetes-pods"} 196170
prometheus_target_metadata_cache_bytes{scrape_job="kubernetes-pods-slow"} 0
prometheus_target_metadata_cache_bytes{scrape_job="kubernetes-service-endpoints"} 29066
prometheus_target_metadata_cache_bytes{scrape_job="kubernetes-service-endpoints-slow"} 0
prometheus_target_metadata_cache_bytes{scrape_job="kubernetes-services"} 0
prometheus_target_metadata_cache_bytes{scrape_job="node-info"} 107731
prometheus_target_metadata_cache_bytes{scrape_job="node_exporter"} 0
prometheus_target_metadata_cache_bytes{scrape_job="prometheus"} 11399
prometheus_target_metadata_cache_bytes{scrape_job="prometheus-pushgateway"} 0
# HELP prometheus_target_metadata_cache_entries Total number of metric metadata entries in the cache
# TYPE prometheus_target_metadata_cache_entries gauge
prometheus_target_metadata_cache_entries{scrape_job="envoy-stats"} 7440
prometheus_target_metadata_cache_entries{scrape_job="istiod"} 168
prometheus_target_metadata_cache_entries{scrape_job="kubernetes-apiservers"} 184
prometheus_target_metadata_cache_entries{scrape_job="kubernetes-nodes"} 508
prometheus_target_metadata_cache_entries{scrape_job="kubernetes-nodes-cadvisor"} 268
prometheus_target_metadata_cache_entries{scrape_job="kubernetes-pods"} 10011
prometheus_target_metadata_cache_entries{scrape_job="kubernetes-pods-slow"} 0
prometheus_target_metadata_cache_entries{scrape_job="kubernetes-service-endpoints"} 482
prometheus_target_metadata_cache_entries{scrape_job="kubernetes-service-endpoints-slow"} 0
prometheus_target_metadata_cache_entries{scrape_job="kubernetes-services"} 0
prometheus_target_metadata_cache_entries{scrape_job="node-info"} 2266
prometheus_target_metadata_cache_entries{scrape_job="node_exporter"} 0
prometheus_target_metadata_cache_entries{scrape_job="prometheus"} 185
prometheus_target_metadata_cache_entries{scrape_job="prometheus-pushgateway"} 0
# HELP prometheus_target_scrape_pool_exceeded_label_limits_total Total number of times scrape pools hit the label limits, during sync or config reload.
# TYPE prometheus_target_scrape_pool_exceeded_label_limits_total counter
prometheus_target_scrape_pool_exceeded_label_limits_total 0
# HELP prometheus_target_scrape_pool_exceeded_target_limit_total Total number of times scrape pools hit the target limit, during sync or config reload.
# TYPE prometheus_target_scrape_pool_exceeded_target_limit_total counter
prometheus_target_scrape_pool_exceeded_target_limit_total 0
# HELP prometheus_target_scrape_pool_reloads_failed_total Total number of failed scrape pool reloads.
# TYPE prometheus_target_scrape_pool_reloads_failed_total counter
prometheus_target_scrape_pool_reloads_failed_total 0
# HELP prometheus_target_scrape_pool_reloads_total Total number of scrape pool reloads.
# TYPE prometheus_target_scrape_pool_reloads_total counter
prometheus_target_scrape_pool_reloads_total 0
# HELP prometheus_target_scrape_pool_sync_total Total number of syncs that were executed on a scrape pool.
# TYPE prometheus_target_scrape_pool_sync_total counter
prometheus_target_scrape_pool_sync_total{scrape_job="envoy-stats"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="istiod"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="kubernetes-apiservers"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="kubernetes-nodes"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="kubernetes-nodes-cadvisor"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="kubernetes-pods"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="kubernetes-pods-slow"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="kubernetes-service-endpoints"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="kubernetes-service-endpoints-slow"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="kubernetes-services"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="node-info"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="node_exporter"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="prometheus"} 205
prometheus_target_scrape_pool_sync_total{scrape_job="prometheus-pushgateway"} 205
# HELP prometheus_target_scrape_pool_targets Current number of targets in this scrape pool.
# TYPE prometheus_target_scrape_pool_targets gauge
prometheus_target_scrape_pool_targets{scrape_job="envoy-stats"} 37
prometheus_target_scrape_pool_targets{scrape_job="istiod"} 2
prometheus_target_scrape_pool_targets{scrape_job="kubernetes-apiservers"} 1
prometheus_target_scrape_pool_targets{scrape_job="kubernetes-nodes"} 4
prometheus_target_scrape_pool_targets{scrape_job="kubernetes-nodes-cadvisor"} 4
prometheus_target_scrape_pool_targets{scrape_job="kubernetes-pods"} 40
prometheus_target_scrape_pool_targets{scrape_job="kubernetes-pods-slow"} 0
prometheus_target_scrape_pool_targets{scrape_job="kubernetes-service-endpoints"} 11
prometheus_target_scrape_pool_targets{scrape_job="kubernetes-service-endpoints-slow"} 0
prometheus_target_scrape_pool_targets{scrape_job="kubernetes-services"} 0
prometheus_target_scrape_pool_targets{scrape_job="node-info"} 4
prometheus_target_scrape_pool_targets{scrape_job="node_exporter"} 1
prometheus_target_scrape_pool_targets{scrape_job="prometheus"} 1
prometheus_target_scrape_pool_targets{scrape_job="prometheus-pushgateway"} 0
# HELP prometheus_target_scrape_pools_failed_total Total number of scrape pool creations that failed.
# TYPE prometheus_target_scrape_pools_failed_total counter
prometheus_target_scrape_pools_failed_total 0
# HELP prometheus_target_scrape_pools_total Total number of scrape pool creation attempts.
# TYPE prometheus_target_scrape_pools_total counter
prometheus_target_scrape_pools_total 14
# HELP prometheus_target_scrapes_cache_flush_forced_total How many times a scrape cache was flushed due to getting big while scrapes are failing.
# TYPE prometheus_target_scrapes_cache_flush_forced_total counter
prometheus_target_scrapes_cache_flush_forced_total 0
# HELP prometheus_target_scrapes_exceeded_body_size_limit_total Total number of scrapes that hit the body size limit
# TYPE prometheus_target_scrapes_exceeded_body_size_limit_total counter
prometheus_target_scrapes_exceeded_body_size_limit_total 0
# HELP prometheus_target_scrapes_exceeded_sample_limit_total Total number of scrapes that hit the sample limit and were rejected.
# TYPE prometheus_target_scrapes_exceeded_sample_limit_total counter
prometheus_target_scrapes_exceeded_sample_limit_total 0
# HELP prometheus_target_scrapes_exemplar_out_of_order_total Total number of exemplar rejected due to not being out of the expected order.
# TYPE prometheus_target_scrapes_exemplar_out_of_order_total counter
prometheus_target_scrapes_exemplar_out_of_order_total 0
# HELP prometheus_target_scrapes_sample_duplicate_timestamp_total Total number of samples rejected due to duplicate timestamps but different values.
# TYPE prometheus_target_scrapes_sample_duplicate_timestamp_total counter
prometheus_target_scrapes_sample_duplicate_timestamp_total 0
# HELP prometheus_target_scrapes_sample_out_of_bounds_total Total number of samples rejected due to timestamp falling outside of the time bounds.
# TYPE prometheus_target_scrapes_sample_out_of_bounds_total counter
prometheus_target_scrapes_sample_out_of_bounds_total 0
# HELP prometheus_target_scrapes_sample_out_of_order_total Total number of samples rejected due to not being out of the expected order.
# TYPE prometheus_target_scrapes_sample_out_of_order_total counter
prometheus_target_scrapes_sample_out_of_order_total 0
# HELP prometheus_target_sync_failed_total Total number of target sync failures.
# TYPE prometheus_target_sync_failed_total counter
prometheus_target_sync_failed_total{scrape_job="envoy-stats"} 0
prometheus_target_sync_failed_total{scrape_job="istiod"} 0
prometheus_target_sync_failed_total{scrape_job="kubernetes-apiservers"} 0
prometheus_target_sync_failed_total{scrape_job="kubernetes-nodes"} 0
prometheus_target_sync_failed_total{scrape_job="kubernetes-nodes-cadvisor"} 0
prometheus_target_sync_failed_total{scrape_job="kubernetes-pods"} 0
prometheus_target_sync_failed_total{scrape_job="kubernetes-pods-slow"} 0
prometheus_target_sync_failed_total{scrape_job="kubernetes-service-endpoints"} 0
prometheus_target_sync_failed_total{scrape_job="kubernetes-service-endpoints-slow"} 0
prometheus_target_sync_failed_total{scrape_job="kubernetes-services"} 0
prometheus_target_sync_failed_total{scrape_job="node-info"} 0
prometheus_target_sync_failed_total{scrape_job="node_exporter"} 0
prometheus_target_sync_failed_total{scrape_job="prometheus"} 0
prometheus_target_sync_failed_total{scrape_job="prometheus-pushgateway"} 0
# HELP prometheus_target_sync_length_seconds Actual interval to sync the scrape pool.
# TYPE prometheus_target_sync_length_seconds summary
prometheus_target_sync_length_seconds{scrape_job="envoy-stats",quantile="0.01"} 0.002854258
prometheus_target_sync_length_seconds{scrape_job="envoy-stats",quantile="0.05"} 0.002858909
prometheus_target_sync_length_seconds{scrape_job="envoy-stats",quantile="0.5"} 0.003441838
prometheus_target_sync_length_seconds{scrape_job="envoy-stats",quantile="0.9"} 0.00537348
prometheus_target_sync_length_seconds{scrape_job="envoy-stats",quantile="0.99"} 0.011295656
prometheus_target_sync_length_seconds_sum{scrape_job="envoy-stats"} 52.59998319500003
prometheus_target_sync_length_seconds_count{scrape_job="envoy-stats"} 205
prometheus_target_sync_length_seconds{scrape_job="istiod",quantile="0.01"} 0.00067903
prometheus_target_sync_length_seconds{scrape_job="istiod",quantile="0.05"} 0.000680926
prometheus_target_sync_length_seconds{scrape_job="istiod",quantile="0.5"} 0.000978827
prometheus_target_sync_length_seconds{scrape_job="istiod",quantile="0.9"} 0.001281479
prometheus_target_sync_length_seconds{scrape_job="istiod",quantile="0.99"} 0.004934515
prometheus_target_sync_length_seconds_sum{scrape_job="istiod"} 7.880272620000002
prometheus_target_sync_length_seconds_count{scrape_job="istiod"} 205
prometheus_target_sync_length_seconds{scrape_job="kubernetes-apiservers",quantile="0.01"} 0.00195131
prometheus_target_sync_length_seconds{scrape_job="kubernetes-apiservers",quantile="0.05"} 0.001966964
prometheus_target_sync_length_seconds{scrape_job="kubernetes-apiservers",quantile="0.5"} 0.002392252
prometheus_target_sync_length_seconds{scrape_job="kubernetes-apiservers",quantile="0.9"} 0.003903984
prometheus_target_sync_length_seconds{scrape_job="kubernetes-apiservers",quantile="0.99"} 0.009881119
prometheus_target_sync_length_seconds_sum{scrape_job="kubernetes-apiservers"} 0.534366006
prometheus_target_sync_length_seconds_count{scrape_job="kubernetes-apiservers"} 205
prometheus_target_sync_length_seconds{scrape_job="kubernetes-nodes",quantile="0.01"} 0.000890475
prometheus_target_sync_length_seconds{scrape_job="kubernetes-nodes",quantile="0.05"} 0.000909726
prometheus_target_sync_length_seconds{scrape_job="kubernetes-nodes",quantile="0.5"} 0.001281088
prometheus_target_sync_length_seconds{scrape_job="kubernetes-nodes",quantile="0.9"} 0.001759896
prometheus_target_sync_length_seconds{scrape_job="kubernetes-nodes",quantile="0.99"} 0.005511689
prometheus_target_sync_length_seconds_sum{scrape_job="kubernetes-nodes"} 0.2886534349999999
prometheus_target_sync_length_seconds_count{scrape_job="kubernetes-nodes"} 205
prometheus_target_sync_length_seconds{scrape_job="kubernetes-nodes-cadvisor",quantile="0.01"} 0.000897311
prometheus_target_sync_length_seconds{scrape_job="kubernetes-nodes-cadvisor",quantile="0.05"} 0.00090826
prometheus_target_sync_length_seconds{scrape_job="kubernetes-nodes-cadvisor",quantile="0.5"} 0.001005934
prometheus_target_sync_length_seconds{scrape_job="kubernetes-nodes-cadvisor",quantile="0.9"} 0.002796661
prometheus_target_sync_length_seconds{scrape_job="kubernetes-nodes-cadvisor",quantile="0.99"} 0.005742336
prometheus_target_sync_length_seconds_sum{scrape_job="kubernetes-nodes-cadvisor"} 0.29340900999999975
prometheus_target_sync_length_seconds_count{scrape_job="kubernetes-nodes-cadvisor"} 205
prometheus_target_sync_length_seconds{scrape_job="kubernetes-pods",quantile="0.01"} 0.006499608
prometheus_target_sync_length_seconds{scrape_job="kubernetes-pods",quantile="0.05"} 0.006502108
prometheus_target_sync_length_seconds{scrape_job="kubernetes-pods",quantile="0.5"} 0.007261953
prometheus_target_sync_length_seconds{scrape_job="kubernetes-pods",quantile="0.9"} 0.009121609
prometheus_target_sync_length_seconds{scrape_job="kubernetes-pods",quantile="0.99"} 0.015594283
prometheus_target_sync_length_seconds_sum{scrape_job="kubernetes-pods"} 47.99796328699995
prometheus_target_sync_length_seconds_count{scrape_job="kubernetes-pods"} 205
prometheus_target_sync_length_seconds{scrape_job="kubernetes-pods-slow",quantile="0.01"} 0.002531944
prometheus_target_sync_length_seconds{scrape_job="kubernetes-pods-slow",quantile="0.05"} 0.002545028
prometheus_target_sync_length_seconds{scrape_job="kubernetes-pods-slow",quantile="0.5"} 0.003120724
prometheus_target_sync_length_seconds{scrape_job="kubernetes-pods-slow",quantile="0.9"} 0.004861966
prometheus_target_sync_length_seconds{scrape_job="kubernetes-pods-slow",quantile="0.99"} 0.010600225
prometheus_target_sync_length_seconds_sum{scrape_job="kubernetes-pods-slow"} 0.673523332
prometheus_target_sync_length_seconds_count{scrape_job="kubernetes-pods-slow"} 205
prometheus_target_sync_length_seconds{scrape_job="kubernetes-service-endpoints",quantile="0.01"} 0.002326353
prometheus_target_sync_length_seconds{scrape_job="kubernetes-service-endpoints",quantile="0.05"} 0.002341947
prometheus_target_sync_length_seconds{scrape_job="kubernetes-service-endpoints",quantile="0.5"} 0.002850995
prometheus_target_sync_length_seconds{scrape_job="kubernetes-service-endpoints",quantile="0.9"} 0.00539108
prometheus_target_sync_length_seconds{scrape_job="kubernetes-service-endpoints",quantile="0.99"} 0.010232545
prometheus_target_sync_length_seconds_sum{scrape_job="kubernetes-service-endpoints"} 0.6281039069999996
prometheus_target_sync_length_seconds_count{scrape_job="kubernetes-service-endpoints"} 205
prometheus_target_sync_length_seconds{scrape_job="kubernetes-service-endpoints-slow",quantile="0.01"} 0.001928099
prometheus_target_sync_length_seconds{scrape_job="kubernetes-service-endpoints-slow",quantile="0.05"} 0.001945322
prometheus_target_sync_length_seconds{scrape_job="kubernetes-service-endpoints-slow",quantile="0.5"} 0.002488588
prometheus_target_sync_length_seconds{scrape_job="kubernetes-service-endpoints-slow",quantile="0.9"} 0.003622486
prometheus_target_sync_length_seconds{scrape_job="kubernetes-service-endpoints-slow",quantile="0.99"} 0.009561507
prometheus_target_sync_length_seconds_sum{scrape_job="kubernetes-service-endpoints-slow"} 0.5375068120000004
prometheus_target_sync_length_seconds_count{scrape_job="kubernetes-service-endpoints-slow"} 205
prometheus_target_sync_length_seconds{scrape_job="kubernetes-services",quantile="0.01"} 0.000413933
prometheus_target_sync_length_seconds{scrape_job="kubernetes-services",quantile="0.05"} 0.000441215
prometheus_target_sync_length_seconds{scrape_job="kubernetes-services",quantile="0.5"} 0.000612334
prometheus_target_sync_length_seconds{scrape_job="kubernetes-services",quantile="0.9"} 0.000851241
prometheus_target_sync_length_seconds{scrape_job="kubernetes-services",quantile="0.99"} 0.003306856
prometheus_target_sync_length_seconds_sum{scrape_job="kubernetes-services"} 0.14155382899999994
prometheus_target_sync_length_seconds_count{scrape_job="kubernetes-services"} 205
prometheus_target_sync_length_seconds{scrape_job="node-info",quantile="0.01"} 3.5691e-05
prometheus_target_sync_length_seconds{scrape_job="node-info",quantile="0.05"} 3.8528e-05
prometheus_target_sync_length_seconds{scrape_job="node-info",quantile="0.5"} 5.3776e-05
prometheus_target_sync_length_seconds{scrape_job="node-info",quantile="0.9"} 0.000104892
prometheus_target_sync_length_seconds{scrape_job="node-info",quantile="0.99"} 0.000338426
prometheus_target_sync_length_seconds_sum{scrape_job="node-info"} 0.013341694
prometheus_target_sync_length_seconds_count{scrape_job="node-info"} 205
prometheus_target_sync_length_seconds{scrape_job="node_exporter",quantile="0.01"} 9.629e-06
prometheus_target_sync_length_seconds{scrape_job="node_exporter",quantile="0.05"} 9.862e-06
prometheus_target_sync_length_seconds{scrape_job="node_exporter",quantile="0.5"} 2.5856e-05
prometheus_target_sync_length_seconds{scrape_job="node_exporter",quantile="0.9"} 6.6201e-05
prometheus_target_sync_length_seconds{scrape_job="node_exporter",quantile="0.99"} 0.000153461
prometheus_target_sync_length_seconds_sum{scrape_job="node_exporter"} 0.007271858000000001
prometheus_target_sync_length_seconds_count{scrape_job="node_exporter"} 205
prometheus_target_sync_length_seconds{scrape_job="prometheus",quantile="0.01"} 1.2699e-05
prometheus_target_sync_length_seconds{scrape_job="prometheus",quantile="0.05"} 2.2214e-05
prometheus_target_sync_length_seconds{scrape_job="prometheus",quantile="0.5"} 2.9957e-05
prometheus_target_sync_length_seconds{scrape_job="prometheus",quantile="0.9"} 4.502e-05
prometheus_target_sync_length_seconds{scrape_job="prometheus",quantile="0.99"} 0.000169795
prometheus_target_sync_length_seconds_sum{scrape_job="prometheus"} 0.0072702
prometheus_target_sync_length_seconds_count{scrape_job="prometheus"} 205
prometheus_target_sync_length_seconds{scrape_job="prometheus-pushgateway",quantile="0.01"} 0.000393523
prometheus_target_sync_length_seconds{scrape_job="prometheus-pushgateway",quantile="0.05"} 0.000400396
prometheus_target_sync_length_seconds{scrape_job="prometheus-pushgateway",quantile="0.5"} 0.000473403
prometheus_target_sync_length_seconds{scrape_job="prometheus-pushgateway",quantile="0.9"} 0.000739642
prometheus_target_sync_length_seconds{scrape_job="prometheus-pushgateway",quantile="0.99"} 0.002599963
prometheus_target_sync_length_seconds_sum{scrape_job="prometheus-pushgateway"} 0.12966110000000003
prometheus_target_sync_length_seconds_count{scrape_job="prometheus-pushgateway"} 205
# HELP prometheus_template_text_expansion_failures_total The total number of template text expansion failures.
# TYPE prometheus_template_text_expansion_failures_total counter
prometheus_template_text_expansion_failures_total 0
# HELP prometheus_template_text_expansions_total The total number of template text expansions.
# TYPE prometheus_template_text_expansions_total counter
prometheus_template_text_expansions_total 0
# HELP prometheus_treecache_watcher_goroutines The current number of watcher goroutines.
# TYPE prometheus_treecache_watcher_goroutines gauge
prometheus_treecache_watcher_goroutines 0
# HELP prometheus_treecache_zookeeper_failures_total The total number of ZooKeeper failures.
# TYPE prometheus_treecache_zookeeper_failures_total counter
prometheus_treecache_zookeeper_failures_total 0
# HELP prometheus_tsdb_blocks_loaded Number of currently loaded data blocks
# TYPE prometheus_tsdb_blocks_loaded gauge
prometheus_tsdb_blocks_loaded 0
# HELP prometheus_tsdb_checkpoint_creations_failed_total Total number of checkpoint creations that failed.
# TYPE prometheus_tsdb_checkpoint_creations_failed_total counter
prometheus_tsdb_checkpoint_creations_failed_total 0
# HELP prometheus_tsdb_checkpoint_creations_total Total number of checkpoint creations attempted.
# TYPE prometheus_tsdb_checkpoint_creations_total counter
prometheus_tsdb_checkpoint_creations_total 0
# HELP prometheus_tsdb_checkpoint_deletions_failed_total Total number of checkpoint deletions that failed.
# TYPE prometheus_tsdb_checkpoint_deletions_failed_total counter
prometheus_tsdb_checkpoint_deletions_failed_total 0
# HELP prometheus_tsdb_checkpoint_deletions_total Total number of checkpoint deletions attempted.
# TYPE prometheus_tsdb_checkpoint_deletions_total counter
prometheus_tsdb_checkpoint_deletions_total 0
# HELP prometheus_tsdb_clean_start -1: lockfile is disabled. 0: a lockfile from a previous execution was replaced. 1: lockfile creation was clean
# TYPE prometheus_tsdb_clean_start gauge
prometheus_tsdb_clean_start 1
# HELP prometheus_tsdb_compaction_chunk_range_seconds Final time range of chunks on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_range_seconds histogram
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="100"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="400"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="1600"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="6400"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="25600"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="102400"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="409600"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="1.6384e+06"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="6.5536e+06"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="2.62144e+07"} 0
prometheus_tsdb_compaction_chunk_range_seconds_bucket{le="+Inf"} 0
prometheus_tsdb_compaction_chunk_range_seconds_sum 0
prometheus_tsdb_compaction_chunk_range_seconds_count 0
# HELP prometheus_tsdb_compaction_chunk_samples Final number of samples on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_samples histogram
prometheus_tsdb_compaction_chunk_samples_bucket{le="4"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="6"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="9"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="13.5"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="20.25"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="30.375"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="45.5625"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="68.34375"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="102.515625"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="153.7734375"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="230.66015625"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="345.990234375"} 0
prometheus_tsdb_compaction_chunk_samples_bucket{le="+Inf"} 0
prometheus_tsdb_compaction_chunk_samples_sum 0
prometheus_tsdb_compaction_chunk_samples_count 0
# HELP prometheus_tsdb_compaction_chunk_size_bytes Final size of chunks on their first compaction
# TYPE prometheus_tsdb_compaction_chunk_size_bytes histogram
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="32"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="48"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="72"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="108"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="162"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="243"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="364.5"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="546.75"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="820.125"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="1230.1875"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="1845.28125"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="2767.921875"} 0
prometheus_tsdb_compaction_chunk_size_bytes_bucket{le="+Inf"} 0
prometheus_tsdb_compaction_chunk_size_bytes_sum 0
prometheus_tsdb_compaction_chunk_size_bytes_count 0
# HELP prometheus_tsdb_compaction_duration_seconds Duration of compaction runs
# TYPE prometheus_tsdb_compaction_duration_seconds histogram
prometheus_tsdb_compaction_duration_seconds_bucket{le="1"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="2"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="4"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="8"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="16"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="32"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="64"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="128"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="256"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="512"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="1024"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="2048"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="4096"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="8192"} 0
prometheus_tsdb_compaction_duration_seconds_bucket{le="+Inf"} 0
prometheus_tsdb_compaction_duration_seconds_sum 0
prometheus_tsdb_compaction_duration_seconds_count 0
# HELP prometheus_tsdb_compaction_populating_block Set to 1 when a block is currently being written to the disk.
# TYPE prometheus_tsdb_compaction_populating_block gauge
prometheus_tsdb_compaction_populating_block 0
# HELP prometheus_tsdb_compactions_failed_total Total number of compactions that failed for the partition.
# TYPE prometheus_tsdb_compactions_failed_total counter
prometheus_tsdb_compactions_failed_total 0
# HELP prometheus_tsdb_compactions_skipped_total Total number of skipped compactions due to disabled auto compaction.
# TYPE prometheus_tsdb_compactions_skipped_total counter
prometheus_tsdb_compactions_skipped_total 0
# HELP prometheus_tsdb_compactions_total Total number of compactions that were executed for the partition.
# TYPE prometheus_tsdb_compactions_total counter
prometheus_tsdb_compactions_total 0
# HELP prometheus_tsdb_compactions_triggered_total Total number of triggered compactions for the partition.
# TYPE prometheus_tsdb_compactions_triggered_total counter
prometheus_tsdb_compactions_triggered_total 83
# HELP prometheus_tsdb_data_replay_duration_seconds Time taken to replay the data on disk.
# TYPE prometheus_tsdb_data_replay_duration_seconds gauge
prometheus_tsdb_data_replay_duration_seconds 0.00023992
# HELP prometheus_tsdb_exemplar_exemplars_appended_total Total number of appended exemplars.
# TYPE prometheus_tsdb_exemplar_exemplars_appended_total counter
prometheus_tsdb_exemplar_exemplars_appended_total 0
# HELP prometheus_tsdb_exemplar_exemplars_in_storage Number of exemplars currently in circular storage.
# TYPE prometheus_tsdb_exemplar_exemplars_in_storage gauge
prometheus_tsdb_exemplar_exemplars_in_storage 0
# HELP prometheus_tsdb_exemplar_last_exemplars_timestamp_seconds The timestamp of the oldest exemplar stored in circular storage. Useful to check for what timerange the current exemplar buffer limit allows. This usually means the last timestampfor all exemplars for a typical setup. This is not true though if one of the series timestamp is in future compared to rest series.
# TYPE prometheus_tsdb_exemplar_last_exemplars_timestamp_seconds gauge
prometheus_tsdb_exemplar_last_exemplars_timestamp_seconds 0
# HELP prometheus_tsdb_exemplar_max_exemplars Total number of exemplars the exemplar storage can store, resizeable.
# TYPE prometheus_tsdb_exemplar_max_exemplars gauge
prometheus_tsdb_exemplar_max_exemplars 0
# HELP prometheus_tsdb_exemplar_out_of_order_exemplars_total Total number of out of order exemplar ingestion failed attempts.
# TYPE prometheus_tsdb_exemplar_out_of_order_exemplars_total counter
prometheus_tsdb_exemplar_out_of_order_exemplars_total 0
# HELP prometheus_tsdb_exemplar_series_with_exemplars_in_storage Number of series with exemplars currently in circular storage.
# TYPE prometheus_tsdb_exemplar_series_with_exemplars_in_storage gauge
prometheus_tsdb_exemplar_series_with_exemplars_in_storage 0
# HELP prometheus_tsdb_head_active_appenders Number of currently active appender transactions
# TYPE prometheus_tsdb_head_active_appenders gauge
prometheus_tsdb_head_active_appenders 0
# HELP prometheus_tsdb_head_chunks Total number of chunks in the head block.
# TYPE prometheus_tsdb_head_chunks gauge
prometheus_tsdb_head_chunks 451149
# HELP prometheus_tsdb_head_chunks_created_total Total number of chunks created in the head
# TYPE prometheus_tsdb_head_chunks_created_total counter
prometheus_tsdb_head_chunks_created_total 451149
# HELP prometheus_tsdb_head_chunks_removed_total Total number of chunks removed in the head
# TYPE prometheus_tsdb_head_chunks_removed_total counter
prometheus_tsdb_head_chunks_removed_total 0
# HELP prometheus_tsdb_head_gc_duration_seconds Runtime of garbage collection in the head block.
# TYPE prometheus_tsdb_head_gc_duration_seconds summary
prometheus_tsdb_head_gc_duration_seconds_sum 0
prometheus_tsdb_head_gc_duration_seconds_count 0
# HELP prometheus_tsdb_head_max_time Maximum timestamp of the head block. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_head_max_time gauge
prometheus_tsdb_head_max_time 1.698412072757e+12
# HELP prometheus_tsdb_head_max_time_seconds Maximum timestamp of the head block.
# TYPE prometheus_tsdb_head_max_time_seconds gauge
prometheus_tsdb_head_max_time_seconds 1.698412072e+09
# HELP prometheus_tsdb_head_min_time Minimum time bound of the head block. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_head_min_time gauge
prometheus_tsdb_head_min_time 1.698407066187e+12
# HELP prometheus_tsdb_head_min_time_seconds Minimum time bound of the head block.
# TYPE prometheus_tsdb_head_min_time_seconds gauge
prometheus_tsdb_head_min_time_seconds 1.698407066e+09
# HELP prometheus_tsdb_head_out_of_order_samples_appended_total Total number of appended out of order samples.
# TYPE prometheus_tsdb_head_out_of_order_samples_appended_total counter
prometheus_tsdb_head_out_of_order_samples_appended_total 0
# HELP prometheus_tsdb_head_samples_appended_total Total number of appended samples.
# TYPE prometheus_tsdb_head_samples_appended_total counter
prometheus_tsdb_head_samples_appended_total{type="float"} 3.467365e+07
prometheus_tsdb_head_samples_appended_total{type="histogram"} 0
# HELP prometheus_tsdb_head_series Total number of series in the head block.
# TYPE prometheus_tsdb_head_series gauge
prometheus_tsdb_head_series 162154
# HELP prometheus_tsdb_head_series_created_total Total number of series created in the head
# TYPE prometheus_tsdb_head_series_created_total counter
prometheus_tsdb_head_series_created_total 162154
# HELP prometheus_tsdb_head_series_not_found_total Total number of requests for series that were not found.
# TYPE prometheus_tsdb_head_series_not_found_total counter
prometheus_tsdb_head_series_not_found_total 0
# HELP prometheus_tsdb_head_series_removed_total Total number of series removed in the head
# TYPE prometheus_tsdb_head_series_removed_total counter
prometheus_tsdb_head_series_removed_total 0
# HELP prometheus_tsdb_head_truncations_failed_total Total number of head truncations that failed.
# TYPE prometheus_tsdb_head_truncations_failed_total counter
prometheus_tsdb_head_truncations_failed_total 0
# HELP prometheus_tsdb_head_truncations_total Total number of head truncations attempted.
# TYPE prometheus_tsdb_head_truncations_total counter
prometheus_tsdb_head_truncations_total 0
# HELP prometheus_tsdb_isolation_high_watermark The highest TSDB append ID that has been given out.
# TYPE prometheus_tsdb_isolation_high_watermark gauge
prometheus_tsdb_isolation_high_watermark 34293
# HELP prometheus_tsdb_isolation_low_watermark The lowest TSDB append ID that is still referenced.
# TYPE prometheus_tsdb_isolation_low_watermark gauge
prometheus_tsdb_isolation_low_watermark 34293
# HELP prometheus_tsdb_lowest_timestamp Lowest timestamp value stored in the database. The unit is decided by the library consumer.
# TYPE prometheus_tsdb_lowest_timestamp gauge
prometheus_tsdb_lowest_timestamp 1.698407066187e+12
# HELP prometheus_tsdb_lowest_timestamp_seconds Lowest timestamp value stored in the database.
# TYPE prometheus_tsdb_lowest_timestamp_seconds gauge
prometheus_tsdb_lowest_timestamp_seconds 1.698407066e+09
# HELP prometheus_tsdb_mmap_chunk_corruptions_total Total number of memory-mapped chunk corruptions.
# TYPE prometheus_tsdb_mmap_chunk_corruptions_total counter
prometheus_tsdb_mmap_chunk_corruptions_total 0
# HELP prometheus_tsdb_out_of_bound_samples_total Total number of out of bound samples ingestion failed attempts with out of order support disabled.
# TYPE prometheus_tsdb_out_of_bound_samples_total counter
prometheus_tsdb_out_of_bound_samples_total{type="float"} 0
# HELP prometheus_tsdb_out_of_order_samples_total Total number of out of order samples ingestion failed attempts due to out of order being disabled.
# TYPE prometheus_tsdb_out_of_order_samples_total counter
prometheus_tsdb_out_of_order_samples_total{type="float"} 0
prometheus_tsdb_out_of_order_samples_total{type="histogram"} 0
# HELP prometheus_tsdb_reloads_failures_total Number of times the database failed to reloadBlocks block data from disk.
# TYPE prometheus_tsdb_reloads_failures_total counter
prometheus_tsdb_reloads_failures_total 0
# HELP prometheus_tsdb_reloads_total Number of times the database reloaded block data from disk.
# TYPE prometheus_tsdb_reloads_total counter
prometheus_tsdb_reloads_total 84
# HELP prometheus_tsdb_retention_limit_bytes Max number of bytes to be retained in the tsdb blocks, configured 0 means disabled
# TYPE prometheus_tsdb_retention_limit_bytes gauge
prometheus_tsdb_retention_limit_bytes 0
# HELP prometheus_tsdb_size_retentions_total The number of times that blocks were deleted because the maximum number of bytes was exceeded.
# TYPE prometheus_tsdb_size_retentions_total counter
prometheus_tsdb_size_retentions_total 0
# HELP prometheus_tsdb_snapshot_replay_error_total Total number snapshot replays that failed.
# TYPE prometheus_tsdb_snapshot_replay_error_total counter
prometheus_tsdb_snapshot_replay_error_total 0
# HELP prometheus_tsdb_storage_blocks_bytes The number of bytes that are currently used for local storage by all blocks.
# TYPE prometheus_tsdb_storage_blocks_bytes gauge
prometheus_tsdb_storage_blocks_bytes 0
# HELP prometheus_tsdb_symbol_table_size_bytes Size of symbol table in memory for loaded blocks
# TYPE prometheus_tsdb_symbol_table_size_bytes gauge
prometheus_tsdb_symbol_table_size_bytes 0
# HELP prometheus_tsdb_time_retentions_total The number of times that blocks were deleted because the maximum time limit was exceeded.
# TYPE prometheus_tsdb_time_retentions_total counter
prometheus_tsdb_time_retentions_total 0
# HELP prometheus_tsdb_tombstone_cleanup_seconds The time taken to recompact blocks to remove tombstones.
# TYPE prometheus_tsdb_tombstone_cleanup_seconds histogram
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.005"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.01"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.025"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.05"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.1"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.25"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="0.5"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="1"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="2.5"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="5"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="10"} 0
prometheus_tsdb_tombstone_cleanup_seconds_bucket{le="+Inf"} 0
prometheus_tsdb_tombstone_cleanup_seconds_sum 0
prometheus_tsdb_tombstone_cleanup_seconds_count 0
# HELP prometheus_tsdb_too_old_samples_total Total number of out of order samples ingestion failed attempts with out of support enabled, but sample outside of time window.
# TYPE prometheus_tsdb_too_old_samples_total counter
prometheus_tsdb_too_old_samples_total{type="float"} 0
# HELP prometheus_tsdb_vertical_compactions_total Total number of compactions done on overlapping blocks.
# TYPE prometheus_tsdb_vertical_compactions_total counter
prometheus_tsdb_vertical_compactions_total 0
# HELP prometheus_tsdb_wal_completed_pages_total Total number of completed pages.
# TYPE prometheus_tsdb_wal_completed_pages_total counter
prometheus_tsdb_wal_completed_pages_total 6454
# HELP prometheus_tsdb_wal_corruptions_total Total number of WAL corruptions.
# TYPE prometheus_tsdb_wal_corruptions_total counter
prometheus_tsdb_wal_corruptions_total 0
# HELP prometheus_tsdb_wal_fsync_duration_seconds Duration of write log fsync.
# TYPE prometheus_tsdb_wal_fsync_duration_seconds summary
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.5"} NaN
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.9"} NaN
prometheus_tsdb_wal_fsync_duration_seconds{quantile="0.99"} NaN
prometheus_tsdb_wal_fsync_duration_seconds_sum 0.016987999
prometheus_tsdb_wal_fsync_duration_seconds_count 1
# HELP prometheus_tsdb_wal_page_flushes_total Total number of page flushes.
# TYPE prometheus_tsdb_wal_page_flushes_total counter
prometheus_tsdb_wal_page_flushes_total 41123
# HELP prometheus_tsdb_wal_segment_current Write log segment index that TSDB is currently writing to.
# TYPE prometheus_tsdb_wal_segment_current gauge
prometheus_tsdb_wal_segment_current 1
# HELP prometheus_tsdb_wal_truncate_duration_seconds Duration of WAL truncation.
# TYPE prometheus_tsdb_wal_truncate_duration_seconds summary
prometheus_tsdb_wal_truncate_duration_seconds_sum 0
prometheus_tsdb_wal_truncate_duration_seconds_count 0
# HELP prometheus_tsdb_wal_truncations_failed_total Total number of write log truncations that failed.
# TYPE prometheus_tsdb_wal_truncations_failed_total counter
prometheus_tsdb_wal_truncations_failed_total 0
# HELP prometheus_tsdb_wal_truncations_total Total number of write log truncations attempted.
# TYPE prometheus_tsdb_wal_truncations_total counter
prometheus_tsdb_wal_truncations_total 0
# HELP prometheus_tsdb_wal_writes_failed_total Total number of write log writes that failed.
# TYPE prometheus_tsdb_wal_writes_failed_total counter
prometheus_tsdb_wal_writes_failed_total 0
# HELP prometheus_web_federation_errors_total Total number of errors that occurred while sending federation responses.
# TYPE prometheus_web_federation_errors_total counter
prometheus_web_federation_errors_total 0
# HELP prometheus_web_federation_warnings_total Total number of warnings that occurred while sending federation responses.
# TYPE prometheus_web_federation_warnings_total counter
prometheus_web_federation_warnings_total 0
# HELP promhttp_metric_handler_requests_in_flight Current number of scrapes being served.
# TYPE promhttp_metric_handler_requests_in_flight gauge
promhttp_metric_handler_requests_in_flight 1
# HELP promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code.
# TYPE promhttp_metric_handler_requests_total counter
promhttp_metric_handler_requests_total{code="200"} 333
promhttp_metric_handler_requests_total{code="500"} 0
promhttp_metric_handler_requests_total{code="503"} 0
